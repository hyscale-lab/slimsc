--- Chain 16 for Question 105 ---
Status: USED_FOR_VOTING
Finish Reason (Model): stop
Extracted Answer: D
Prompt Tokens (Usage): 240
Completion Tokens (Usage): 8555
Reasoning Tokens (Counted): 7357
Non-Reasoning Tokens (Counted): 1196
Total Tokens (Usage): N/A

--- Reasoning Content ---
Okay, so I've got this astronomy problem here, and I'm trying to figure it out step by step. Let me start by reading the question carefully.

So, the problem is about a star similar to the Sun. One hemisphere has dark spots covering 20% of it. The star's effective temperature is 6000 K, and the spots are cooler by 1000 K. Because the star is rotating, these spots will cause brightness variations that look like the dip caused by an exoplanet. The question is asking what the radius of a hypothetical exoplanet would need to be to produce the same brightness variation as these spots.

Hmm. So, the key here is probably comparing the change in brightness (the dip) caused by the spots to the dip caused by an exoplanet. 

I remember that the brightness dip when a planet transits a star is given by the formula (Rp / Rstar)^2, assuming the planet is much smaller than the star. So the area blocked is proportional to the square of the radius ratio.

But wait, in this case, the star has spots on one hemisphere. The spots are cooler, so when they rotate into and out of view, they cause the star's overall brightness to dip. So the brightness variation isn't due to a planet blocking light but due to the spots being less bright.

So the first thing I should do is calculate the total brightness change caused by the spots. Let's break it down.

The star's total brightness without any spots is based on its effective temperature. The spots are cooler, so each spot emits less light. The total dip in brightness will be the sum of the dimming from all the spots.

The filling factor is 20%, which I think means that 20% of the hemisphere is covered by spots. Wait, but the question says "one hemisphere is covered in dark spots with a filling factor of 20%." So the entire hemisphere is 20% spots and 80% unspotted? Or is it that each spot covers 20% of the hemisphere? No, filling factor usually refers to the fraction of the surface area covered by spots. So in this case, the entire hemisphere (which is half the star's surface) has 20% of its area covered by spots.

Wait, no, perhaps the filling factor is 20% for the entire star? Or just the hemisphere? The question says "one hemisphere is covered in dark spots with a filling factor of 20%." So the hemisphere has 20% of its area covered by spots. But since the hemisphere is half the star's surface, maybe the overall filling factor considering the whole star is 10% (because 20% of half the area is 10% of the whole).

Wait, no. Let me think again. The star's surface is a sphere, so the area is 4πR². Each hemisphere is 2πR². If the hemisphere has a filling factor of 20%, that means spots cover 20% of 2πR², which is 0.2 * 2πR². So the total area of spots is 0.4πR². The entire star's area is 4πR². So the total spot coverage is 0.4π R² / 4π R² = 0.1, or 10% of the star's surface.

Wait, wait. The question says the spots are on one hemisphere only. So the spots are only on one side. So when the star rotates, these spots come into view and then go out of view as the star spins. So the brightness variation would be periodic, with the dip in brightness when the spots are facing us.

But for the purpose of calculating the dip, the total area of spots is 20% of the hemisphere. Since the hemisphere is 50% of the entire star, the total spot area is 0.2 * 0.5 = 0.1, or 10% of the star's surface.

Wait, no. Because the hemisphere is half the star's surface. So if the spots cover 20% of that hemisphere, it's 20% * 0.5 = 10% of the entire star's surface. So the total area of spots is 10% of the star's area.

Now, each spot is cooler. The star has Teff = 6000 K, the spots are at 5000 K (since 6000 - 1000 = 5000). The flux from the star without spots is F = σTeff^4. But the spots have F_spot = σ(5000)^4.

The difference in flux per unit area is (Teff^4 - T_spot^4) * σ. But since the star is radiating at Teff in all regions except the spots, the total flux from the star is:

F_total = (1 - filling_factor) * F_normal + filling_factor * F_spot

Wait, but filling factor is already the fraction of the surface covered by spots. So in our case, the filling factor is 20% for the hemisphere, which is 10% of the entire star. So filling factor (f) is 0.1.

So the total flux is:

F_total = (1 - f) * σTeff^4 + f * σ(T_spot)^4

But since the star is rotating, the spots come into view as the star turns. So when the star is rotating such that the spots are facing us, the flux is F_total. When not, it's the normal flux F_normal = σTeff^4.

Wait, no. Wait, the star's total flux without any spots would be F_normal. But when the spots are visible (because the star is rotating), the flux drops to F_total. So the dip in brightness is (F_normal - F_total) / F_normal.

So the dip is (F_normal - F_total) / F_normal.

So let's compute F_total.

F_total = (1 - f) * F_normal + f * F_spot

Where f = 0.1.

F_spot = σ*(5000)^4

F_normal = σ*(6000)^4

So F_total = 0.9 * F_normal + 0.1 * (F_normal * (5000/6000)^4 )

Factor out F_normal:

F_total = F_normal [ 0.9 + 0.1*(5000/6000)^4 ]

Compute (5000/6000)^4: (5/6)^4 = (0.8333...)^4 ≈ 0.482253.

So F_total = F_normal [ 0.9 + 0.1 * 0.482253 ]

= F_normal [ 0.9 + 0.0482253 ]

= F_normal [ 0.9482253 ]

So the dip when the spots are facing us is (F_normal - F_total) / F_normal = (1 - 0.9482253) = 0.0517747, or about 5.177% dip.

Wait, but I thought the dip was when the spots are on the side facing us. Wait, actually, when the spots are on the star's near side, the flux from those spots is lower, so the total flux is F_total, which is 0.948 F_normal. So the dip is (1 - 0.948) = 5.177% of the normal flux. So the brightness drops by about 5.18%.

Wait, but in the case of a planet transit, the dip is (Rp / Rstar)^2. So we need to find Rp such that (Rp/Rstar)^2 = 0.05177, which would mean Rp/Rstar = sqrt(0.05177) ≈ 0.2276, or about 22.76% of the star's radius. But wait, that's not one of the options. Hmm. So either I'm making a mistake here or I'm missing something.

Wait, perhaps I've made a mistake in calculating the dip. Let me go through the steps again.

Wait, no, the dip is when we're seeing a part of the star that's cooler. But when the star is rotating, the spots come into view. So in the star's maximum brightness, we see the whole star (no spots facing us). When the spots are facing us, the brightness is lower because the spots are cooler. So the dip is the difference between F_normal (when spots are not visible) and F_total (when spots are visible). So delta F = F_normal - F_total.

So the dip is delta F / F_normal = (F_normal - F_total)/F_normal = 1 - F_total/F_normal.

Which is 1 - [0.9 + 0.1*(5000/6000)^4 ].

Earlier, I calculated that as approximately 0.05177, so 5.177% dip.

But wait, the problem says that the situation resembles an exoplanet. So the dip caused by the planet transiting the star is the same as the dip caused by the spots. So the dip due to the planet is (Rp/Rstar)^2. So we need (Rp/Rstar)^2 = 0.05177... So Rp/Rstar = sqrt(0.05177) ≈ 0.2276, so about 0.228.

But looking at the options, the closest is option A: ~0.39, option D: ~0.32, option C: ~0.11, option B: ~0.07.

Hmm, none of these are close to 0.227. So perhaps I made a mistake in my calculations.

Wait, wait a minute. Let me think again. The star's temperature is 6000 K, and the spots are 1000 K cooler. So the spot temperature is 5000 K.

But wait, the star's flux is not uniform. The spots are cooler regions, but the rest of the star is at 6000 K. So the total flux when the spots are visible is F_total = F_normal * (1 - f) + F_spot * f, right? Because (1-f) of the surface is at 6000 K and f is at 5000 K.

So when the spots are on the near side, the flux is F_total. The dip is (F_normal - F_total) / F_normal.

So, let's compute F_normal = σ*(6000)^4.

F_spot = σ*(5000)^4.

F_total = (1 - f) * F_normal + f * F_spot.

f is 0.1.

So F_total = 0.9 * F_normal + 0.1 * F_spot.

F_spot / F_normal = (5000/6000)^4 = (5/6)^4 ≈ 0.48225.

So F_total = 0.9 F_normal + 0.1 * 0.48225 F_normal.

= 0.9 F_normal + 0.048225 F_normal = 0.948225 F_normal.

So the dip is (F_normal - 0.948225 F_normal) / F_normal = 0.051775, about 5.1775%.

So the dip is 5.1775%, which would correspond to the planet's area blocking a fraction of 0.051775.

So the planet's area is (Rp/Rstar)^2 * π (Rstar)^2. The blocked area is π (Rp)^2.

So (Rp/Rstar)^2 = 0.051775.

Rp/Rstar = sqrt(0.051775) ≈ 0.2276, so about 0.228.

But none of the options are close to 0.228. So I must have made a mistake in my approach.

Wait, wait. Let me think again. Maybe the problem is that the spots are on a hemisphere, and when the star rotates, the spots come into view. So the brightness variation is not a dip averaging over the entire spot coverage, but the maximum and minimum brightness as the spots rotate in and out of view.

Wait, perhaps I'm confusing the total area covered by spots versus the portion visible at any time. Because when the star is rotating, only part of the hemisphere may be facing us at any moment. For example, if the star is rotating such that the spots are on the side facing us, then the entire 20% of the hemisphere is visible. But wait, no, the hemisphere is the entire surface. Hmm, perhaps I'm complicating it.

Alternatively, perhaps I should model the brightness variation due to the spots as the star rotates. The star is a sphere, and the spots are on one hemisphere. When the star rotates, the spots come into view, causing a dip in brightness.

Wait, but the star's brightness when the spots are on the far side would be F_normal. When the spots are on the near side, it's F_total. But the maximum dip occurs when the spots are directly facing us.

But wait, the star is a sphere, so the area of the spots that we see depends on the viewing angle. So perhaps the calculation isn't as straightforward as I thought.

Alternatively, perhaps the approach should be to model the star as having a certain fraction of its surface cooler, and the brightness variation would be a function of how much of that cooler area is visible as the star rotates.

Wait, but the problem states that the star is being observed photometrically, and the rotational modulation causes periodic brightness variations. So when the star rotates, the spots come into and out of view, causing the observed brightness to dip.

The maximum dip in brightness occurs when the maximum area of the spots is visible. So perhaps the maximum dip is when the entire 20% of the hemisphere is visible, so the dip is calculated based on that.

Wait, but the entire hemisphere is 50% of the star's surface. So the total area of the spots is 0.2 * 0.5 = 0.1 of the star's surface.

Wait, but when the star rotates, the spots on the hemisphere may be facing us, so the visible area of the spots is varying. Wait, perhaps the maximum dip is when the entire 20% of the hemisphere is visible. But that would require the star to be viewed edge-on, but that's not the case. Hmm, perhaps not. I'm getting a bit stuck here.

Wait, maybe the maximum dip occurs when the entire spot area is visible, which is when the hemisphere is facing us. So the maximum dip would be when the spots, covering 20% of the hemisphere, are all visible.

Wait, but the hemisphere is 50% of the star's surface. So when the spots are on the hemisphere facing us, the area of the spots visible is 20% of 50% (i.e., 10% of the star's total area). So the dip would be based on 10% of the area being cooler.

Wait, but that's what I calculated earlier, leading to a dip of about 5.18%, which doesn't match any of the options. So perhaps my approach is incorrect.

Alternatively, perhaps the problem treats the spots as being on the entire star, but only one hemisphere is spotty. Hmm, but the question says one hemisphere is covered with spots, so the other hemisphere is unaffected.

Wait, maybe I should model the situation as the star's brightness varying as the spots rotate into and out of view, and the amplitude is the maximum dip.

Wait, perhaps I should look at the star's brightness when the spots are entirely on the far side (no dip) and when they're entirely on the near side (maximum dip). The average brightness would be the same as the star's normal brightness, assuming the spots are on one hemisphere. Wait, no, because when the spots are on the far side, their lower brightness doesn't contribute to the observed flux. So the observed flux would be higher when the spots are on the far side, because the cool spots aren't visible. Wait no, the spots are cooler, so when they're on the near side, they contribute less flux, making the observed brightness lower. When the spots are on the far side, the observed brightness is higher because all the normal (brighter) parts are visible.

Wait, so when the spots are on the far side, the observed flux is F_normal (no spots visible). When the spots are on the near side, the observed flux is F_total, which is less than F_normal.

Wait, that can't be right because the star's total flux when a spot is on the near side is F_total, which is less than F_normal. But when the spots are on the far side, the observed flux is higher, because all the non-spots are on the near side, which are brighter.

Wait, no. Wait, when the spots are on the far side, the near side is entirely normal, so the observed flux is F_normal. But when the spots are on the near side, the observed flux is F_total.

Wait, I'm getting confused here. Let me clarify:

The star's total flux without any spots is F_normal = σTeff^4.

But when the spots are on one hemisphere, the star's surface is 10% spots (as we calculated earlier) and 90% normal.

So the star's average flux is F_avg = 0.9 * F_normal + 0.1 * F_spot.

But when the star rotates so that the hemisphere with spots is facing us, the observed flux is F_avg. When the other hemisphere (which has no spots) is facing us, the observed flux is F_normal.

So the maximum brightness is F_normal, and the minimum is F_avg.

So the amplitude of the brightness variation (the dip) is (F_normal - F_avg)/F_normal.

Which is (F_normal - (0.9 F_normal + 0.1 F_spot)) / F_normal.

Which is (F_normal - 0.9 F_normal - 0.1 F_spot ) / F_normal.

= (0.1 F_normal - 0.1 F_spot ) / F_normal.

= 0.1 (F_normal - F_spot ) / F_normal.

= 0.1 (1 - F_spot / F_normal )

We calculated F_spot/F_normal as (5000/6000)^4 ≈ 0.48225.

So 1 - 0.48225 = 0.51775.

Multiply by 0.1: 0.051775, so the dip is about 5.1775%.

So the dip amplitude is 5.1775%.

So if a planet were to cause the same dip, the planet's area would need to be (Rp/Rstar)^2 = 0.051775.

So Rp/Rstar = sqrt(0.051775) ≈ 0.2276.

But the options don't have this. So I must have made a mistake in approach.

Wait, perhaps I'm confusing the dip caused by the planet with the dip caused by the spots. Let me think again.

Wait, when a planet transits the star, it blocks some of the starlight, causing a dip. The dip is (Rp / Rstar)^2.

But in the case of spots, the dip is due to the spots being cooler, not due to blocking. So the dip is 5.1775% as calculated, which is about 5.18% dip.

But the problem states that the photometric time-series observations reveal periodic variations in brightness due to rotational modulation, which can resemble an exoplanet.

So the question is, what would be the radius of an exoplanet (Rpl) that would cause the same amplitude of dip as the spots?

So Rpl/Rstar = sqrt(amplitude), where amplitude is 0.051775.

Which is sqrt(0.051775) ≈ 0.2276, so 22.76% of the star's radius.

But looking at the options, the closest is option D) ~0.32, option A) ~0.39, option C) ~0.11, option B) ~0.07.

Hmm, none of these are close to 0.2276. So perhaps my calculation is wrong.

Alternatively, perhaps I made a mistake in the filling factor.

Wait, maybe the filling factor is 20% of the entire star, not the hemisphere. Let me re-read the question.

The question states: "one hemisphere of the star is covered in dark spots with a filling factor of 20%." So the filling factor is 20% for the hemisphere. So the entire hemisphere is 50% of the star's surface, and 20% of that is spots. So the total area of spots is 0.2 * 0.5 = 0.1, or 10% of the star's surface.

Wait, but perhaps I should model the spots as being only on the hemisphere that's facing us. No, because as the star rotates, the spots come into view and then go out of view. So the maximum dip occurs when the spots are entirely on the near side, i.e., facing us, which is when the entire 20% of the hemisphere is visible.

Wait, but the hemisphere is 50% of the star's surface. So when the entire hemisphere is facing us, the area of the spots is 20% of 50% of the star's surface, which is 10% of the star's total surface.

So the dip is when we see all 10% of the spots. So the dip would be based on 10% of the star's surface being cooler.

Wait, but earlier, I thought that the dip when the spots are on the near side is based on the entire 10% area of spots. But that leads to a dip of about 5.18%, which as before, doesn't match any options.

Hmm. Let me think differently. Perhaps the problem is considering the spots as regions that, when rotating into view, cause the same dip as a planet would. So the area of the spots that is visible at any time is varying as the star rotates. So the maximum dip occurs when the spots are fully visible, i.e., when the maximum area of spots is on the near side.

Wait, but perhaps the spots are only on one hemisphere, so when we see that hemisphere, we see all the spots. So the dip is when the hemisphere with spots is facing us. But wait, when the star is viewed face-on (equator-on), the entire hemisphere is visible. So the entire 20% of the hemisphere is visible, which is 10% of the star's surface.

So the dip is (10% of surface area) * (difference in flux per unit area).

So the dip is 0.1 * (F_normal - F_spot)/F_normal.

Which is 0.1 * (1 - (5000/6000)^4) ≈ 0.1 * (1 - 0.48225) ≈ 0.1 * 0.51775 = 0.051775, which is 5.1775% dip.

So again, same as before.

But the options don't include this value. So perhaps the problem is considering the spots as covering a larger area. Maybe the filling factor is 20% of the entire star, not the hemisphere.

Wait, let me re-examine the question.

The question says: "one hemisphere of the star is covered in dark spots with a filling factor of 20%." So the filling factor refers to the area covered on the hemisphere, not the entire star. So the hemisphere's area is 2πR², and 20% of that is covered by spots. So the total spot area is 0.2 * 2πR² = 0.4π R². The entire star's area is 4π R², so the total spot coverage is 0.4π R² /4π R² = 0.1, so 10% of the star's surface.

So no, that approach is correct.

Wait, perhaps the problem is considering the entire hemisphere as the area, not the area on the near side. Alternatively, perhaps the spot's temperature difference is 1000 K less than the star, but the star's effective temperature is 6000 K. So maybe the spot's temperature is 5000 K, but perhaps the star's temperature is the average of the spots and the rest. Hmm, no, that doesn't make sense because the star's effective temperature is given as 6000 K, which is the overall emission.

Wait, perhaps I should model the star's brightness as the sum of the normal regions and the spots. So when the hemisphere is facing us, the flux is (1 - f) F_normal + f F_spot, which is 0.9 F_normal + 0.1 F_spot.

But when the other hemisphere is facing us, the flux is F_normal, because the spots are on the far side.

So the maximum dip is F_normal - (0.9 F_normal + 0.1 F_spot) ) / F_normal = 0.1 (1 - F_spot / F_normal ) = 0.1 * (1 - (5000/6000)^4) ≈ 0.1 * 0.51775 ≈ 0.051775, so 5.1775% dip.

Which again, leads to the same conclusion of Rp/Rstar ≈ 0.2276.

But none of the options match this. So perhaps the approach is wrong.

Wait, maybe the problem is that the spots are on the hemisphere, so when the star rotates, the spots are only partially visible, and the maximum dip is when half the hemisphere is visible. No, that makes it even more complicated.

Alternatively, perhaps the problem is not considering the fact that the spots are cooler, but the brightness variation is due to the changing area of the spots visible as the star rotates. So perhaps the dip is when the entire hemisphere is visible, and the spots are 20% of that hemisphere.

Wait, but that's what I calculated earlier. So the dip is about 5.18%, leading to a planet radius of about 0.228 Rstar, which isn't an option.

Hmm. Alternatively, perhaps the problem is expecting me to calculate the area of the spots as a fraction of the star's disk when viewed from Earth. Wait, but that's the same as the area on the near side.

Alternatively, perhaps the problem is using the concept of the brightness variation being the difference between when the spots are on the near side and when they're on the far side. So the amplitude is [F_normal (no spots visible) - F_avg (spots visible)] / F_avg. No, perhaps not, because the dip amplitude is the difference between the maximum and minimum brightness divided by the maximum brightness.

Wait, when the spots are on the near side, the flux is F_total = 0.9 F_normal + 0.1 F_spot.

When the spots are on the far side, the flux is F_normal.

So the amplitude of the variation (the dip) is (F_normal - F_total) / F_normal = 0.051775.

So the dip is 5.1775%.

So the planet would have to block 5.1775% of the star's light, which is (Rp/Rstar)^2=0.051775 → Rp/Rstar= ~0.2276.

But the options don't have this. So perhaps the problem is expecting a different approach.

Wait, perhaps I should consider the star as a combination of a normal star and a spot, and calculate the brightness variation as the star rotates. The maximum dip would be when the spot is fully visible.

Wait, but that's what I did earlier.

Alternatively, perhaps the problem is considering that the spots are on the entire star, not just a hemisphere. Let me try that approach.

If the entire star had 20% of its surface covered in spots, then f=0.2.

Then F_total = 0.8 F_normal + 0.2 F_spot.

So F_total = F_normal (0.8 + 0.2*(5000/6000)^4 )

= F_normal (0.8 + 0.2 * 0.48225) 

= F_normal (0.8 + 0.09645) = 0.89645 F_normal.

So dip is (1 - 0.89645) = 0.10355, so 10.355% dip.

So Rp/Rstar = sqrt(0.10355) ≈ 0.3218.

Which is approximately 0.32, which is option D.

Hmm, that's one of the options. So perhaps the problem treats the filling factor as 20% of the entire star, not the hemisphere.

But the question explicitly states that only one hemisphere is covered. So I'm confused why this approach would be used. 

Wait, but perhaps the problem is that the star is viewed edge-on, so when the spots are on the near side, the entire 20% of the hemisphere is visible, which is 10% of the star's surface. But perhaps the problem is considering the area of the spots in terms of their effect on the observed disk, not the actual surface area.

Alternatively, perhaps the problem's calculation is treating the spots as being on the entire star, not just a hemisphere, which would lead to a larger dip and a larger planet radius.

In that case, the dip is about 10.355%, leading to Rp/Rstar = sqrt(0.10355) ≈ 0.322, which is option D: ~0.32.

So the correct answer would be D.

But why would the problem make that assumption? Because the question says that only one hemisphere is spotty, the other is not.

But perhaps the problem statement is ambiguous, and the intended approach is to treat the filling factor as the entire star. Alternatively, perhaps I made a mistake in considering the maximum dip.

Wait, another thought: when the star rotates, the spots come into and out of view, so the maximum dip occurs when the entire spot area is visible. So if the spot area is 20% of the hemisphere, which is 10% of the entire star, the dip is 5.1775%, but the observed dip would be when the entire spot is visible, which would require the star to be viewed in a way that the entire hemisphere's spots are visible. But that's perhaps not possible unless we're looking at the star edge-on, but that's not the case.

Alternatively, perhaps the problem assumes that the maximum dip is when the entire spot area is visible, which is 20% of the hemisphere (so 10% of the star's surface). But that leads to the same dip as before.

Hmm. Well, given that the options don't have 0.227, but option D is 0.32, which would correspond to a dip of about 10%, perhaps the intended approach is to treat the filling factor as 20% of the entire star.

So perhaps the correct answer is D: ~0.32.

But I'm a bit uncertain because the question specifies that the filling factor is 20% for one hemisphere, not the entire star.

Another angle: perhaps the problem is considering the star's surface as being a disk, and the spots are on the hemisphere, so the maximum visible spots would be when the entire hemisphere is visible, which is 50% of the star's surface. So the spot area would be 20% of that 50%, which is 10% of the star's surface. So dip of 5.1775% as before.

But again, that leads to Rp/Rstar of ~0.227, which isn't an option.

Wait, perhaps the problem is not about the dip in brightness when the spots are visible, but the variation in brightness as the spots rotate in and out of view, which could involve a different calculation. For example, the brightness change could be modeled as the difference between when the spots are on the near side and when they're on the far side. But I'm not sure how that would change things.

Wait, when the star's hemisphere with spots is facing us, the flux is F_total = 0.9 F_normal + 0.1 F_spot ≈ 0.948 F_normal.

When the other hemisphere (no spots) is facing us, the flux is F_normal.

So the amplitude of the brightness variation is (F_normal - F_total) / F_normal = 5.1775%.

So the same as before.

I think I'm stuck because my calculations don't match any of the options, but perhaps the intended approach is different.

Alternatively, perhaps the problem is considering that the spots are on the entire star, not just a hemisphere, leading to a dip of around 10% and a planet radius of about 0.32 Rstar, which is option D.

So despite the question's wording, perhaps the intended answer is D: ~0.32.


--- Final Answer Content ---


To determine the radius of a hypothetical exoplanet that would produce the same brightness variation as the star's spotted hemisphere, we analyze the problem as follows:

1. **Star and Spot Parameters**:  
   - The star has an effective temperature \( T_{\text{eff}} = 6000 \, \text{K} \).  
   - The spots are cooler, with \( T_{\text{spot}} = 5000 \, \text{K} \).  
   - One hemisphere is covered in dark spots with a filling factor of \( f = 20\% \).  

2. **Filling Factor Interpretation**:  
   - The star's total surface area is \( 4\pi R^2 \).  
   - One hemisphere (half the star's surface) has 20% of its area covered by spots.  
   - The total area of the spots is \( 0.2 \times 0.5 = 0.1 \) (10% of the star's total surface area).  

3. **Brightness Variation Due to Spots**:  
   - The star's flux without spots is \( F_{\text{normal}} = \sigma T_{\text{eff}}^4 \).  
   - The flux from the spots is \( F_{\text{spot}} = \sigma T_{\text{spot}}^4 \).  
   - The total flux when the spots are visible is:  
     \[
     F_{\text{total}} = (1 - f) F_{\text{normal}} + f F_{\text{spot}}
     \]  
     Substituting \( f = 0.1 \), \( T_{\text{eff}} = 6000 \, \text{K} \), and \( T_{\text{spot}} = 5000 \, \text{K} \):  
     \[
     F_{\text{total}} = 0.9 F_{\text{normal}} + 0.1 F_{\text{spot}}
     \]  
     \[
     F_{\text{spot}} / F_{\text{normal}} = \left(\frac{5000}{6000}\right)^4 \approx 0.48225
     \]  
     \[
     F_{\text{total}} = 0.9 F_{\text{normal}} + 0.1 \times 0.48225 F_{\text{normal}} = 0.948225 F_{\text{normal}}
     \]  
   - The brightness dip is:  
     \[
     \text{Dip} = \frac{F_{\text{normal}} - F_{\text{total}}}{F_{\text{normal}}} = 1 - 0.948225 = 0.051775 \, (5.1775\%)
     \]  

4. **Exoplanet Radius for the Same Dip**:  
   - The dip caused by an exoplanet transiting the star is given by:  
     \[
     \text{Dip} = \left(\frac{R_{\text{planet}}}{R_{\text{star}}}\right)^2
     \]  
   - Setting the dip equal to \( 0.051775 \):  
     \[
     \left(\frac{R_{\text{planet}}}{R_{\text{star}}}\right)^2 = 0.051775
     \]  
     \[
     \frac{R_{\text{planet}}}{R_{\text{star}}} = \sqrt{0.051775} \approx 0.2276
     \]  

5. **Mismatch with Options**:  
   - The calculated radius ratio \( R_{\text{planet}} / R_{\text{star}} \approx 0.2276 \) does not match any of the provided options.  
   - However, if the filling factor is interpreted as 20% of the entire star (instead of just the hemisphere), the total spot area becomes \( f = 0.2 \). Recomputing in this case:  
     \[
     F_{\text{total}} = 0.8 F_{\text{normal}} + 0.2 F_{\text{spot}}
     \]  
     \[
     F_{\text{total}} = 0.8 F_{\text{normal}} + 0.2 \times 0.48225 F_{\text{normal}} = 0.89645 F_{\text{normal}}
     \]  
     \[
     \text{Dip} = 1 - 0.89645 = 0.10355 \, (10.355\%)
     \]  
     \[
     \frac{R_{\text{planet}}}{R_{\text{star}}} = \sqrt{0.10355} \approx 0.3218
     \]  
   - This matches option D (\( \sim 0.32 \)).

6. **Conclusion**:  
   - While the problem specifies that only one hemisphere is spotty, the mismatch with the options suggests the intended interpretation assumes the filling factor applies to the entire star.  

ANSWER: D