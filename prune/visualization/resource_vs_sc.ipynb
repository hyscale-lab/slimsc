{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f25b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58af49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path for results\n",
    "user = os.environ.get(\"USER\", \"default_user\")\n",
    "BASE_RESULTS_PATH = Path(\"/home/users/ntu/{user}/slimsc/prune/results\".format(user=user))\n",
    "\n",
    "# Model specific configurations\n",
    "MODEL_CONFIGS = {\n",
    "    \"R1-Distill-Qwen-14B\": {\n",
    "        \"total_gpu_memory_gib\": 39.56 * 2,\n",
    "        \"model_weights_gib\": 15.41 * 2,\n",
    "        \"activation_memory_gib\": 2.95,\n",
    "    },\n",
    "    \"QwQ-32B\": {\n",
    "        \"total_gpu_memory_gib\": 39.56 * 4,\n",
    "        \"model_weights_gib\": 13.95 * 4,\n",
    "        \"activation_memory_gib\": 10.15,\n",
    "    }\n",
    "}\n",
    "\n",
    "GPU_MEMORY_UTILIZATION = 0.9\n",
    "PRECOMPUTED_CACHE_USAGE_FILENAME = \"precomputed_mean_gpu_cache_perc.txt\"\n",
    "\n",
    "# Datasets and Models to process\n",
    "# You can extend these lists if needed\n",
    "MODELS_TO_PROCESS = [\"QwQ-32B\", \"R1-Distill-Qwen-14B\"]\n",
    "DATASETS_TO_PROCESS = [\"aqua_rat\", \"gpqa_diamond\", \"aime\"]\n",
    "\n",
    "# Plotting configuration\n",
    "PLOT_OUTPUT_DIR = \"plots\" # Directory to save the plots\n",
    "PLOT_FILENAME_TEMPLATE_MEMORY = \"memory_{dataset_name}.png\"\n",
    "PLOT_FILENAME_TEMPLATE_TOKENS = \"tokens_{dataset_name}.png\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=cm.tab10.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d23d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precomputed_mean_gpu_cache_usage_perc(run_path: Path):\n",
    "    \"\"\"\n",
    "    Retrieves the precomputed mean_gpu_cache_usage_perc from the file\n",
    "    saved by the precomputation script.\n",
    "    \"\"\"\n",
    "    precomputed_file_path = run_path / PRECOMPUTED_CACHE_USAGE_FILENAME\n",
    "    if not precomputed_file_path.exists():\n",
    "        warnings.warn(f\"Precomputed file '{PRECOMPUTED_CACHE_USAGE_FILENAME}' not found in {run_path}. \"\n",
    "                      f\"Please run the precomputation script.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(precomputed_file_path, 'r') as f:\n",
    "            value_str = f.read().strip()\n",
    "            return float(value_str)\n",
    "    except (IOError, ValueError) as e:\n",
    "        warnings.warn(f\"Error reading or parsing precomputed file {precomputed_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_total_time_for_run(run_path: Path):\n",
    "    \"\"\"\n",
    "    Calculates total processing time from aggregated_metrics.json.\n",
    "    \"\"\"\n",
    "    metrics_file = run_path / \"aggregated_metrics.json\"\n",
    "    if not metrics_file.exists():\n",
    "        warnings.warn(f\"aggregated_metrics.json not found in {run_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics_data = json.load(f)\n",
    "        \n",
    "        mean_duration = float(metrics_data[\"metrics\"][\"mean_processing_duration_sec_per_question\"])\n",
    "        num_questions = int(metrics_data[\"metrics\"][\"num_questions_processed\"])\n",
    "        return mean_duration * num_questions\n",
    "    except (KeyError, ValueError, TypeError) as e:\n",
    "        warnings.warn(f\"Error processing {metrics_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_mean_kv_cache_memory_gib(model_name: str, mean_gpu_cache_usage_perc: float):\n",
    "    \"\"\"\n",
    "    Calculates the mean KV cache memory in GiB based on the formula.\n",
    "    \"\"\"\n",
    "    if model_name not in MODEL_CONFIGS:\n",
    "        warnings.warn(f\"Model {model_name} not found in MODEL_CONFIGS.\")\n",
    "        return None\n",
    "    if mean_gpu_cache_usage_perc is None: # Important check\n",
    "        return None\n",
    "\n",
    "    config = MODEL_CONFIGS[model_name]\n",
    "    \n",
    "    torch_available_memory = (\n",
    "        GPU_MEMORY_UTILIZATION * config[\"total_gpu_memory_gib\"]\n",
    "        - config[\"model_weights_gib\"]\n",
    "        - config[\"activation_memory_gib\"]\n",
    "    )\n",
    "    \n",
    "    if torch_available_memory < 0:\n",
    "        warnings.warn(f\"Calculated torch_available_memory is negative for {model_name}. Check config.\")\n",
    "        torch_available_memory = 0 # Prevent negative memory\n",
    "\n",
    "    mean_kv_mem_gib = torch_available_memory * mean_gpu_cache_usage_perc\n",
    "    return mean_kv_mem_gib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85fe4148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: QwQ-32B / aqua_rat / sc_32_control (sc_i=32)\n",
      "Processing: QwQ-32B / aqua_rat / sc_8_control (sc_i=8)\n",
      "Processing: QwQ-32B / aqua_rat / sc_2_control (sc_i=2)\n",
      "Processing: QwQ-32B / aqua_rat / sc_16_control (sc_i=16)\n",
      "Processing: QwQ-32B / aqua_rat / sc_1_control (sc_i=1)\n",
      "Processing: QwQ-32B / gpqa_diamond / sc_32_control (sc_i=32)\n",
      "Processing: QwQ-32B / gpqa_diamond / sc_8_control (sc_i=8)\n",
      "Processing: QwQ-32B / gpqa_diamond / sc_2_control (sc_i=2)\n",
      "Processing: QwQ-32B / gpqa_diamond / sc_16_control (sc_i=16)\n",
      "Processing: QwQ-32B / gpqa_diamond / sc_1_control (sc_i=1)\n",
      "Processing: QwQ-32B / aime / sc_8_control (sc_i=8)\n",
      "Processing: QwQ-32B / aime / sc_2_control (sc_i=2)\n",
      "Processing: QwQ-32B / aime / sc_4_control (sc_i=4)\n",
      "Processing: QwQ-32B / aime / sc_16_control (sc_i=16)\n",
      "Processing: QwQ-32B / aime / sc_1_control (sc_i=1)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_32_control (sc_i=32)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_64_control (sc_i=64)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_8_control (sc_i=8)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_2_control (sc_i=2)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_16_control (sc_i=16)\n",
      "Processing: R1-Distill-Qwen-14B / aqua_rat / sc_1_control (sc_i=1)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_32_control (sc_i=32)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_64_control (sc_i=64)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_8_control (sc_i=8)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_2_control (sc_i=2)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_4_control (sc_i=4)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_16_control (sc_i=16)\n",
      "Processing: R1-Distill-Qwen-14B / gpqa_diamond / sc_1_control (sc_i=1)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_32_control (sc_i=32)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_64_control (sc_i=64)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_8_control (sc_i=8)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_2_control (sc_i=2)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_4_control (sc_i=4)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_16_control (sc_i=16)\n",
      "Processing: R1-Distill-Qwen-14B / aime / sc_1_control (sc_i=1)\n",
      "\n",
      "Processed Data:\n",
      "             model_name  dataset_name  sc_i  mean_gpu_cache_usage_perc  \\\n",
      "0               QwQ-32B          aime     1                   0.023593   \n",
      "1               QwQ-32B          aime     2                   0.041284   \n",
      "2               QwQ-32B          aime     4                   0.073075   \n",
      "3               QwQ-32B          aime     8                   0.137531   \n",
      "4               QwQ-32B          aime    16                   0.248838   \n",
      "5               QwQ-32B      aqua_rat     1                   0.005668   \n",
      "6               QwQ-32B      aqua_rat     2                   0.011263   \n",
      "7               QwQ-32B      aqua_rat     8                   0.036682   \n",
      "8               QwQ-32B      aqua_rat    16                   0.069513   \n",
      "9               QwQ-32B      aqua_rat    32                   0.123724   \n",
      "10              QwQ-32B  gpqa_diamond     1                   0.014659   \n",
      "11              QwQ-32B  gpqa_diamond     2                   0.026444   \n",
      "12              QwQ-32B  gpqa_diamond     8                   0.088036   \n",
      "13              QwQ-32B  gpqa_diamond    16                   0.159895   \n",
      "14              QwQ-32B  gpqa_diamond    32                   0.274535   \n",
      "15  R1-Distill-Qwen-14B          aime     1                   0.023575   \n",
      "16  R1-Distill-Qwen-14B          aime     2                   0.042181   \n",
      "17  R1-Distill-Qwen-14B          aime     4                   0.069960   \n",
      "18  R1-Distill-Qwen-14B          aime     8                   0.126273   \n",
      "19  R1-Distill-Qwen-14B          aime    16                   0.227050   \n",
      "20  R1-Distill-Qwen-14B          aime    32                   0.371254   \n",
      "21  R1-Distill-Qwen-14B          aime    64                   0.263206   \n",
      "22  R1-Distill-Qwen-14B      aqua_rat     1                   0.005998   \n",
      "23  R1-Distill-Qwen-14B      aqua_rat     2                   0.011158   \n",
      "24  R1-Distill-Qwen-14B      aqua_rat     8                   0.038132   \n",
      "25  R1-Distill-Qwen-14B      aqua_rat    16                   0.071071   \n",
      "26  R1-Distill-Qwen-14B      aqua_rat    32                   0.128753   \n",
      "27  R1-Distill-Qwen-14B      aqua_rat    64                   0.212888   \n",
      "28  R1-Distill-Qwen-14B  gpqa_diamond     1                   0.016173   \n",
      "29  R1-Distill-Qwen-14B  gpqa_diamond     2                   0.030382   \n",
      "30  R1-Distill-Qwen-14B  gpqa_diamond     4                   0.057071   \n",
      "31  R1-Distill-Qwen-14B  gpqa_diamond     8                   0.103989   \n",
      "32  R1-Distill-Qwen-14B  gpqa_diamond    16                   0.198077   \n",
      "33  R1-Distill-Qwen-14B  gpqa_diamond    32                   0.352999   \n",
      "34  R1-Distill-Qwen-14B  gpqa_diamond    64                   0.501032   \n",
      "\n",
      "    total_time_s  mean_kv_cache_memory_gib  cost_kv_mem_gib_total_time_s  \\\n",
      "0       10345.20                  1.804083                  1.866360e+04   \n",
      "1       15036.30                  3.156785                  4.746637e+04   \n",
      "2       16322.40                  5.587729                  9.120514e+04   \n",
      "3       16095.58                 10.516464                  1.692686e+05   \n",
      "4       22296.90                 19.027635                  4.242573e+05   \n",
      "5       15430.50                  0.433415                  6.687815e+03   \n",
      "6       19428.46                  0.861200                  1.673178e+04   \n",
      "7       23246.08                  2.804958                  6.520428e+04   \n",
      "8       27729.18                  5.315351                  1.473903e+05   \n",
      "9       37297.36                  9.460712                  3.528596e+05   \n",
      "10      33434.28                  1.120899                  3.747645e+04   \n",
      "11      39778.20                  2.022040                  8.043312e+04   \n",
      "12      55612.26                  6.731797                  3.743704e+05   \n",
      "13      67937.76                 12.226541                  8.306438e+05   \n",
      "14      88797.06                 20.992606                  1.864082e+06   \n",
      "15       5772.00                  0.882583                  5.094270e+03   \n",
      "16       7265.70                  1.579187                  1.147390e+04   \n",
      "17       8512.20                  2.619160                  2.229481e+04   \n",
      "18      10743.00                  4.727419                  5.078666e+04   \n",
      "19      13359.00                  8.500288                  1.135553e+05   \n",
      "20      17883.60                 13.899008                  2.485643e+05   \n",
      "21      21833.40                  9.853909                  2.151443e+05   \n",
      "22      10129.52                  0.224558                  2.274665e+03   \n",
      "23      11554.46                  0.417731                  4.826657e+03   \n",
      "24      15750.54                  1.427570                  2.248500e+04   \n",
      "25      18115.28                  2.660773                  4.820065e+04   \n",
      "26      22534.88                  4.820243                  1.086236e+05   \n",
      "27      33093.66                  7.970086                  2.637593e+05   \n",
      "28      22843.26                  0.605501                  1.383161e+04   \n",
      "29      27133.92                  1.137434                  3.086305e+04   \n",
      "30      31935.42                  2.136619                  6.823383e+04   \n",
      "31      37022.04                  3.893132                  1.441317e+05   \n",
      "32      43150.14                  7.415600                  3.199842e+05   \n",
      "33      57810.06                 13.215584                  7.639937e+05   \n",
      "34     102421.44                 18.757637                  1.921184e+06   \n",
      "\n",
      "    mean_completion_tokens  \n",
      "0                  12101.8  \n",
      "1                  24106.8  \n",
      "2                  49657.0  \n",
      "3                  97267.8  \n",
      "4                 201692.2  \n",
      "5                   2837.0  \n",
      "6                   6179.7  \n",
      "7                  23283.5  \n",
      "8                  47447.2  \n",
      "9                  95298.8  \n",
      "10                  7521.6  \n",
      "11                 14973.9  \n",
      "12                 59459.7  \n",
      "13                118794.7  \n",
      "14                235412.2  \n",
      "15                  9794.1  \n",
      "16                 19280.3  \n",
      "17                 36009.6  \n",
      "18                 74285.0  \n",
      "19                147614.2  \n",
      "20                290216.7  \n",
      "21                579167.9  \n",
      "22                  2299.4  \n",
      "23                  4629.1  \n",
      "24                 18606.9  \n",
      "25                 37070.3  \n",
      "26                 73753.4  \n",
      "27                147942.8  \n",
      "28                  6389.3  \n",
      "29                 13146.6  \n",
      "30                 26724.4  \n",
      "31                 52413.7  \n",
      "32                105445.0  \n",
      "33                210324.6  \n",
      "34                415209.2  \n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model_name in MODELS_TO_PROCESS:\n",
    "    for dataset_name in DATASETS_TO_PROCESS:\n",
    "        dataset_path = BASE_RESULTS_PATH / model_name / dataset_name\n",
    "        if not dataset_path.is_dir():\n",
    "            warnings.warn(f\"Dataset path not found: {dataset_path}\")\n",
    "            continue\n",
    "\n",
    "        sc_run_dirs = [d for d in dataset_path.iterdir() if d.is_dir() and re.match(r\"sc_\\d+_control\", d.name)]\n",
    "\n",
    "        for run_dir in sc_run_dirs:\n",
    "            run_name = run_dir.name \n",
    "            match = re.match(r\"sc_(\\d+)_control\", run_name)\n",
    "            if not match:\n",
    "                warnings.warn(f\"Could not parse sc_i from directory name: {run_name}\")\n",
    "                continue\n",
    "            \n",
    "            sc_i = int(match.group(1))\n",
    "\n",
    "            print(f\"Processing: {model_name} / {dataset_name} / {run_name} (sc_i={sc_i})\")\n",
    "\n",
    "            # 1. Get the precomputed KV cache usage percentage\n",
    "            mean_gpu_cache_usage_perc = get_precomputed_mean_gpu_cache_usage_perc(run_dir)\n",
    "            if mean_gpu_cache_usage_perc is None:\n",
    "                print(f\"  Skipping {run_name} due to missing or invalid precomputed KV cache usage percentage.\")\n",
    "                continue # Skip this run entirely if cache perc is missing\n",
    "\n",
    "            # 2. Get metrics from aggregated_metrics.json\n",
    "            metrics_file = run_dir / \"aggregated_metrics.json\"\n",
    "            total_time_s = None\n",
    "            mean_completion_tokens = None\n",
    "\n",
    "            if not metrics_file.exists():\n",
    "                warnings.warn(f\"aggregated_metrics.json not found in {run_dir}\")\n",
    "                # We proceed if KV cache perc was found, but total_time_s and tokens will be None\n",
    "            else:\n",
    "                try:\n",
    "                    with open(metrics_file, 'r') as f:\n",
    "                        metrics_data = json.load(f)\n",
    "                    \n",
    "                    # Extract time metrics\n",
    "                    mean_duration = float(metrics_data[\"metrics\"][\"mean_processing_duration_sec_per_question\"])\n",
    "                    num_questions = int(metrics_data[\"metrics\"][\"num_questions_processed\"])\n",
    "                    total_time_s = mean_duration * num_questions\n",
    "\n",
    "                    # Extract completion tokens metric (added)\n",
    "                    mean_completion_tokens_str = metrics_data[\"metrics\"][\"mean_total_completion_tokens_per_question\"]\n",
    "                    mean_completion_tokens = float(mean_completion_tokens_str) # Or int(), depending on desired type\n",
    "\n",
    "                except (KeyError, ValueError, TypeError, json.JSONDecodeError) as e:\n",
    "                    warnings.warn(f\"Error processing {metrics_file}: {e}\")\n",
    "                    # total_time_s and mean_completion_tokens remain None\n",
    "\n",
    "            # 3. Calculate KV memory and cost ONLY if total_time_s was successfully extracted\n",
    "            mean_kv_mem_gib = None\n",
    "            cost = None\n",
    "            if total_time_s is not None:\n",
    "                mean_kv_mem_gib = calculate_mean_kv_cache_memory_gib(model_name, mean_gpu_cache_usage_perc)\n",
    "                if mean_kv_mem_gib is not None: # Should not be None if perc is not None, but good practice\n",
    "                    cost = mean_kv_mem_gib * total_time_s\n",
    "                else:\n",
    "                     warnings.warn(f\"KV cache memory calculation failed for {model_name} with perc {mean_gpu_cache_usage_perc}\")\n",
    "\n",
    "\n",
    "            # Append results - include mean_completion_tokens\n",
    "            all_results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"sc_i\": sc_i,\n",
    "                \"mean_gpu_cache_usage_perc\": mean_gpu_cache_usage_perc, # Still store the precomputed value\n",
    "                \"total_time_s\": total_time_s, # May be None\n",
    "                \"mean_kv_cache_memory_gib\": mean_kv_mem_gib, # May be None\n",
    "                \"cost_kv_mem_gib_total_time_s\": cost, # May be None\n",
    "                \"mean_completion_tokens\": mean_completion_tokens # May be None\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Filter out rows where essential data (like total_time_s for cost, or tokens for tokens plot) is missing\n",
    "# For cost plot: need total_time_s and mean_kv_cache_memory_gib (which depends on perc)\n",
    "# For tokens plot: need mean_completion_tokens\n",
    "# We'll handle skipping missing data specifically in the plotting loops.\n",
    "\n",
    "if not results_df.empty:\n",
    "    results_df = results_df.sort_values(by=[\"model_name\", \"dataset_name\", \"sc_i\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nProcessed Data:\")\n",
    "if not results_df.empty:\n",
    "    print(results_df)\n",
    "else:\n",
    "    print(\"No data was processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1726477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating plots for KV Cache Memory-Time Cost...\n",
      "  Processing dataset: aime\n",
      "    Plot saved to plots/memory_aime.png\n",
      "  Processing dataset: aqua_rat\n",
      "    Plot saved to plots/memory_aqua_rat.png\n",
      "  Processing dataset: gpqa_diamond\n",
      "    Plot saved to plots/memory_gpqa_diamond.png\n",
      "\n",
      "Generating plots for Mean Total Completion Tokens...\n",
      "  Processing dataset: aime\n",
      "    Plot saved to plots/tokens_aime.png\n",
      "  Processing dataset: aqua_rat\n",
      "    Plot saved to plots/tokens_aqua_rat.png\n",
      "  Processing dataset: gpqa_diamond\n",
      "    Plot saved to plots/tokens_gpqa_diamond.png\n",
      "\n",
      "All plots generated and saved.\n"
     ]
    }
   ],
   "source": [
    "if results_df.empty:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    # Ensure plot output directory exists\n",
    "    plot_output_path = Path(PLOT_OUTPUT_DIR)\n",
    "    plot_output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    unique_datasets = results_df['dataset_name'].unique()\n",
    "    unique_models = results_df['model_name'].unique()\n",
    "    \n",
    "    model_styles = {\n",
    "        \"QwQ-32B\": {\"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "        \"R1-Distill-Qwen-14B\": {\"marker\": \"s\", \"linestyle\": \"--\"}\n",
    "    }\n",
    "    default_style = {\"marker\": \"x\", \"linestyle\": \":\"}\n",
    "\n",
    "    # --- Plot 1: KV Cache Memory-Time Cost ---\n",
    "    print(\"\\nGenerating plots for KV Cache Memory-Time Cost...\")\n",
    "    for dataset_name in unique_datasets:\n",
    "        print(f\"  Processing dataset: {dataset_name}\")\n",
    "        # Filter data for this dataset and ensure cost data is available\n",
    "        dataset_df = results_df[\n",
    "            (results_df['dataset_name'] == dataset_name) &\n",
    "            results_df['cost_kv_mem_gib_total_time_s'].notna() # Only plot if cost was calculated\n",
    "        ].copy() # Use .copy() to avoid SettingWithCopyWarning later if needed\n",
    "\n",
    "        if dataset_df.empty:\n",
    "            print(f\"    No valid cost data found for dataset {dataset_name}, skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        \n",
    "        for model_name in unique_models:\n",
    "            model_dataset_df = dataset_df[dataset_df['model_name'] == model_name]\n",
    "            if not model_dataset_df.empty:\n",
    "                model_dataset_df = model_dataset_df.sort_values(by=\"sc_i\")\n",
    "                style = model_styles.get(model_name, default_style)\n",
    "                ax.plot(model_dataset_df['sc_i'], \n",
    "                        model_dataset_df['cost_kv_mem_gib_total_time_s'], \n",
    "                        label=f\"{model_name}\",\n",
    "                        marker=style[\"marker\"],\n",
    "                        linestyle=style[\"linestyle\"])\n",
    "        \n",
    "        ax.set_title(f\"KVC Memory-Time Cost vs. SC Chains\\non '{dataset_name}'\")\n",
    "        ax.set_xlabel(\"Number of Self-Consistency Chains (sc_i)\")\n",
    "        ax.set_ylabel(\"Mean KV Cache Memory (GiB) * Total Time (s)\")\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax.legend(title=\"Model\")\n",
    "        \n",
    "        unique_sc_i_in_dataset = sorted(dataset_df['sc_i'].unique())\n",
    "        if len(unique_sc_i_in_dataset) > 0:\n",
    "             ax.set_xticks(unique_sc_i_in_dataset)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = PLOT_FILENAME_TEMPLATE_MEMORY.format(dataset_name=dataset_name)\n",
    "        save_path = plot_output_path / filename\n",
    "        try:\n",
    "            plt.savefig(save_path, dpi=300)\n",
    "            print(f\"    Plot saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error saving plot {save_path}: {e}\")\n",
    "            \n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- Plot 2: Mean Total Completion Tokens ---\n",
    "    print(\"\\nGenerating plots for Mean Total Completion Tokens...\")\n",
    "    for dataset_name in unique_datasets:\n",
    "        print(f\"  Processing dataset: {dataset_name}\")\n",
    "        # Filter data for this dataset and ensure token data is available\n",
    "        dataset_df = results_df[\n",
    "             (results_df['dataset_name'] == dataset_name) &\n",
    "             results_df['mean_completion_tokens'].notna() # Only plot if tokens were extracted\n",
    "        ].copy()\n",
    "\n",
    "        if dataset_df.empty:\n",
    "            print(f\"    No valid token data found for dataset {dataset_name}, skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        \n",
    "        for model_name in unique_models:\n",
    "            model_dataset_df = dataset_df[dataset_df['model_name'] == model_name]\n",
    "            if not model_dataset_df.empty:\n",
    "                model_dataset_df = model_dataset_df.sort_values(by=\"sc_i\")\n",
    "                style = model_styles.get(model_name, default_style)\n",
    "                ax.plot(model_dataset_df['sc_i'], \n",
    "                        model_dataset_df['mean_completion_tokens'], \n",
    "                        label=f\"{model_name}\",\n",
    "                        marker=style[\"marker\"],\n",
    "                        linestyle=style[\"linestyle\"])\n",
    "        \n",
    "        ax.set_title(f\"Mean Completion Tokens vs. SC Chains\\non '{dataset_name}'\")\n",
    "        ax.set_xlabel(\"Number of Self-Consistency Chains (sc_i)\")\n",
    "        ax.set_ylabel(\"Mean Total Completion Tokens per Question\")\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax.legend(title=\"Model\")\n",
    "        \n",
    "        unique_sc_i_in_dataset = sorted(dataset_df['sc_i'].unique())\n",
    "        if len(unique_sc_i_in_dataset) > 0:\n",
    "             ax.set_xticks(unique_sc_i_in_dataset)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = PLOT_FILENAME_TEMPLATE_TOKENS.format(dataset_name=dataset_name) # Use new template\n",
    "        save_path = plot_output_path / filename\n",
    "        try:\n",
    "            plt.savefig(save_path, dpi=300)\n",
    "            print(f\"    Plot saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error saving plot {save_path}: {e}\")\n",
    "            \n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"\\nAll plots generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b8915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
